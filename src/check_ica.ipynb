{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check ICA\n",
    "The main purpose of the code in this notebook is to:\n",
    "1) preprocess the raw data (high and low pass filter, exclude bad channels)\n",
    "2) identify noise components in the ICA solutions generated in 'run_ica.py'\n",
    "3) removing noise components and applying ICA to the data\n",
    "4) epoching the data\n",
    "\n",
    "To move the epochs to source space use the file 'epochs_2_source_space.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 'visual_29'\n",
    "\n",
    "### RAW DATA ###\n",
    "filepath_raw = f'/media/8.1/raw_data/franscescas_data/raw_data/{session}.fif'\n",
    "\n",
    "# Loading in the raw data\n",
    "raw = mne.io.read_raw_fif(filepath_raw, on_split_missing='warn');\n",
    "raw.load_data();\n",
    "raw.pick_types(meg=True, eeg=False, stim=True)\n",
    "\n",
    "### EXCLUDING BAD CHANNELS ###\n",
    "# loading in the txt file with the channels that should be labeled as bad channels\n",
    "with open('../session_info.txt', 'r') as f:\n",
    "    file = f.read()\n",
    "    session_info = json.loads(file)\n",
    "\n",
    "# using dict[] notation to get the bad channels for the specific file. Not using dict.get() as this does not raise a key-error if the key does not exist\n",
    "bad_channels_file = session_info[session + '.fif']['bad_channels']\n",
    "\n",
    "# marking the channels as bad\n",
    "raw.info['bads'] = bad_channels_file\n",
    "\n",
    "\n",
    "# cropping beginning and end of recording\n",
    "tmin = session_info[session + '.fif']['tmin']\n",
    "tmax = session_info[session + '.fif']['tmax']\n",
    "\n",
    "cropped = raw.copy().crop(tmin = tmin, tmax = tmax)\n",
    "#del raw\n",
    "\n",
    "### HIGH PASS FILTERING ###\n",
    "filt_raw = cropped.copy().filter(l_freq=1, h_freq=40)\n",
    "#del cropped\n",
    "\n",
    "filt_raw.interpolate_bads(origin=(0, 0, 0.04)) \n",
    "\n",
    "\n",
    "### ICA ###\n",
    "ica_filename = f'/media/8.1/intermediate_data/laurap/ica/ica_solution/{session}-ica.fif'\n",
    "ica = mne.preprocessing.read_ica(ica_filename)\n",
    "ica.apply(filt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(filt_raw);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../session_info.txt', 'r') as f:\n",
    "    file = f.read()\n",
    "    session_info = json.loads(file)\n",
    "\n",
    "info_ses = session_info[session + '.fif']['noise_components']\n",
    "noise_components = info_ses\n",
    "\n",
    "ica.plot_properties(filt_raw, picks = noise_components);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = noise_components\n",
    "ica.apply(filt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_raw.save(f'/media/8.1/francescas_data/ica/clean_data_continous_sensor/clean_continuous_sensor_{session}.fif', overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # extracting the events\n",
    "events = mne.find_events(filt_raw, shortest_event=1)\n",
    "\n",
    "# rejection threshold\n",
    "reject = dict(grad=4000e-13, mag=4e-12)  \n",
    "\n",
    "# event ids\n",
    "with open('event_ids.txt', 'r') as f:\n",
    "    file = f.read()\n",
    "    event_ids = json.loads(file)\n",
    "\n",
    "#  creating the epochs\n",
    "epochs = mne.Epochs(filt_raw, events, event_ids, tmin=0, tmax=1, proj=True, baseline=None, preload=True, reject=reject, on_missing = 'warn')\n",
    "\n",
    "outpath = f'/media/8.1/final_data/laurap/epochs/{session}-epo.fif'\n",
    "epochs = epochs.resample(250)\n",
    "epochs.save(outpath, overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c6d417fafcf6fd95c2ae07c3da4aca22733dcf3570acef2375b4229f6bb883b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
